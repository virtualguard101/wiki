# 监督学习与非监督学习

> [Machine Learning | Coursera](https://www.coursera.org/specializations/machine-learning-introduction)

## 监督学习

==**监督学习（*Supervised Learning*）**是指学习 $x$ 到 $y$ 或**输入到输出映射**的算法==，是**更常见**的机器学习方式。

==监督学习的关键特征是我们**给出学习算法示例供计算机学习**==: 给定输入 $x$ 的正确标签 $y$，通过看到正确的输入 $x$ 对和所需的输出标签 $y$， 学习算法最终学会了在没有输出标签的情况下单独获取输入，并对输出做出相当准确的预测或猜测。

!!! example
    - **机器翻译**: 输入 $x$ 是英语，我们希望将其翻译成中文，即希望计算机输出 $y$ 为对应的中文

    - **邮件过滤器**: 输入 $x$ 是电子邮件，我们希望将“垃圾”邮件过滤掉，即希望计算机判断并输出对应输入是否为垃圾邮件（$y = 0/1$）

### 回归算法

以一个例子解释：
!!! example
    假设有一名学生手上有一些他所在的院校的就业率数据，并希望**预测**自己毕业时学校的就业率如何。

根据已有数据，不难绘制数据得出一个就业率关于时间的点阵图。这时，学习算法系统就可以根据你给出的数据**选择**合适的拟合线条来适应这些离散的数据，并根据这个线条的函数给出最终的预测输出。

==所以**回归（*regression*）**是用于**预测连续数值输出**的监督学习算法==，其目标是根据输入特征预测一个连续的数值（如就业率、房价、温度等），通过最小化预测值与真实值之间的误差来训练模型。

!!! abstract
    简单来说，在回归中，学习算法试图根据现有数据建立一个能够准确预测**连续数值**（即从**无限多**的数值中给出**一个预测**）的数学模型，并根据这个数学模型给出与输入对应的预测。

### 分类算法

同样以一个例子解释：
!!! example
    一名医生手上有一名乳腺癌患者的病例信息与一个包含了大量乳腺癌诊断案例的数据集，并试图利用机器学习系统判断这名乳腺癌患者的病灶是良性的还是恶性的。

在本案例中，我们使用 $-1$ 来标记良性肿瘤，使用 $1$ 来标记恶性肿瘤。

由于是举例，我们不妨简化判断模型，先以病灶大小（下图中的横坐标）作为判断指标。

将数据集中的样本数据绘制成[散点图](https://antv.vision/old-site/vis/doc/chart/details/scatter-plot.html)，可能得到类似下图的图片：

<!-- ![散点图案例](scatter_diagram.png)

其中红色表示良性样本，蓝色表示恶性样本，横坐标为肿瘤大小，~~纵坐标表示恶性程度（这个可以先不看）~~。

显然，针对当前的数据模型，我们不需要纵坐标，那么，我们就可以将二维的图像基于上面提到的标识方法压缩成“一维”的: -->

![散点图案例](scatter_example.png)

在这个案例中，机器学习系统显然只需要根据已有数据集对输入案例进行**分类判断**即可。不过需要注意的是，分类并不是只有“二分”这一种模型，二分模型只是最简单的分类算法模型。

!!! abstract
    总的来说，对比回归，**分类算法（*Classification Algorithm*）**则是根据现有数据集建立一个能够尽可能准确预测**离散类别/类别标签**（即从**有限多**的数值中给出**一个预测**）的数学模型，并根据这个数学模型给出与输入对应的预测。

## 非监督学习

**非监督学习（*Unsupervised Learning*）**是在监督学习之后，机器学习中最广泛应用的形式。

以在监督学习中使用的肿瘤判断为例，在非监督学习中，我们没有被要求去诊断肿瘤是良性还是恶性，因为我们没有得到任何标签。相反，在数据集中，我们的任务是发现一些结构、模式或仅仅是在数据中找到一些有趣的东西。

这就是无监督学习，之所以称之为无监督，因为我们并不试图监督算法，为每个输入提供所谓的正确答案——相反，==在无监督学习中，我们要求算法自己去发现数据中有趣的内容，或者可能存在的模式或结构==。

### 聚类算法

对于某个特定的数据集，==一个无监督学习算法可能会决定数据可以被分配到两个不同的组或两个不同的簇中==。因此，它可能会认为这里有一个簇或组，而那里有另一个簇或组。

这种将**未标记的数据（即自身不包含任何类别标签的数据）**分配到不同的群组中的算法，是一种特殊的无监督学习，称为**聚类算法（*Clustering Algorithm*）**。

聚类算法能将未标记的数据分配到不同的群组中，这种方法被广泛应用于多个领域，例如谷歌新闻就采用了聚类技术，其运作方式是每天收集并分析互联网上的数十万篇新闻文章，将相关的报道归类在一起。

!!! example
    再次拿前文提到的那位学生举例，他通过预测发现学校的就业前景并不乐观，于是准备着手了解考研信息，并开始大量关注有关考研的新闻。在关注新闻的过程中，他注意到近期带有"考研"词条的新闻还包含了"就业"、"政策"等词条，**而这个特征同样能被聚类算法捕捉到**。

    聚类算法正在从当天互联网上成千上万的新闻文章中找出那些提及相似词汇的文章，并将它们归入同一类别。令人惊叹的是，这个聚类算法能自行判断哪些词汇表明某些文章属于同一组别。

从人的角度来看，新闻数量如此庞大，每天由人工对所有报道主题进行分类根本不现实。因此，算法必须在无人监督的情况下自行识别出当日新闻的聚类分组。这就是为什么这种聚类算法属于无监督学习算法的范畴。

### 正式定义与其他无监督学习类型

在监督学习中，数据既包含输入 $x$，也包含输出标签 $y$；而在无监督学习中，数据仅包含输入 $x$，没有输出标签 $y$，算法需要从数据中发现某种结构、模式或有趣的信息。

除了**聚类算法（*Clustering Algorithm*）**，还有两种相对常见的无监督学习类型:

- **异常检测（*Anomaly Detection*）**: 用于识别数据中的异常或离群点。这些异常模式通常表示罕见事件、错误或需要特别关注的实例。在金融系统的欺诈检测中非常重要，因为异常交易可能是欺诈的迹象；同时也适用于网络安全入侵检测、设备故障预警、医疗诊断异常识别等多个应用场景。

- **降维技术（*Dimensionality Reduction*）**: 用于将高维数据转换为低维表示，同时尽可能保留原始数据的重要信息。常见的降维方法包括主成分分析（PCA）、t-SNE等。降维的主要目的是减少数据的复杂性、提高计算效率、消除冗余特征，以及便于数据可视化。在图像处理、文本分析、基因表达数据分析等领域有广泛应用。 
